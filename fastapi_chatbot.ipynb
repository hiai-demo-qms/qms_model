{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e4bee34ac20b41b9a4166e0652333f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3a0cec726a54510af55df717d74ee3d",
              "IPY_MODEL_31b1cad8936642d0be316bbc3c2c5342",
              "IPY_MODEL_2a0e51f2358048b795cead94847cb893"
            ],
            "layout": "IPY_MODEL_e05befbd2efa445fb5d681325961f262"
          }
        },
        "a3a0cec726a54510af55df717d74ee3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b860a0407534cbb906281e72f90ec61",
            "placeholder": "​",
            "style": "IPY_MODEL_924b7938731d4e0c8f4c7fee7bdec65e",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "31b1cad8936642d0be316bbc3c2c5342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_710357eb2b4c48cdb81834981fe6cd5a",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa6533bc06374532a477d571f43c6a9e",
            "value": 2
          }
        },
        "2a0e51f2358048b795cead94847cb893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69e92852b95745ee86a4ca4e71f145a4",
            "placeholder": "​",
            "style": "IPY_MODEL_785b6751684b47efa15646c28dc8e37f",
            "value": " 2/2 [00:04&lt;00:00,  1.95s/it]"
          }
        },
        "e05befbd2efa445fb5d681325961f262": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b860a0407534cbb906281e72f90ec61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "924b7938731d4e0c8f4c7fee7bdec65e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "710357eb2b4c48cdb81834981fe6cd5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa6533bc06374532a477d571f43c6a9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69e92852b95745ee86a4ca4e71f145a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "785b6751684b47efa15646c28dc8e37f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install Packages"
      ],
      "metadata": {
        "id": "x_TXPZ31No2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets accelerate peft bitsandbytes\n",
        "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install sentence-transformers faiss-cpu\n",
        "!pip install python-docx PyMuPDF!\n",
        "!pip install PyPDF2\n",
        "!pip install fastapi uvicorn nest-asyncio pyngrok\n",
        "!pip install sqlalchemy pyodbc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StNH0326PBtN",
        "outputId": "37c0f869-550b-4ae3-8717-2ecb1e9c6c6f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.52.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.6.15)\n",
            "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.11.0\n",
            "\u001b[31mERROR: Invalid requirement: 'PyMuPDF!': Expected end or semicolon (after name and no valid version specifier)\n",
            "    PyMuPDF!\n",
            "           ^\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.115.12)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.34.3)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.11-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.46.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.11.7)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.14.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.2.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Downloading pyngrok-7.2.11-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.11\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.11/dist-packages (2.0.41)\n",
            "Collecting pyodbc\n",
            "  Downloading pyodbc-5.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (3.2.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (4.14.0)\n",
            "Downloading pyodbc-5.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (346 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.2/346.2 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyodbc\n",
            "Successfully installed pyodbc-5.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect Drive"
      ],
      "metadata": {
        "id": "Uhmi_L5fNvzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "# Bước 1: Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# #Load RAG Model\n",
        "# zip_path = '/content/drive/My Drive/iso9001-rag-model.zip'\n",
        "# extract_dir = '/content/iso9001-rag-model'\n",
        "\n",
        "# if not os.path.exists(extract_dir):\n",
        "#     print(f\"Extracting zip file to: {extract_dir}\")\n",
        "#     with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "#         zip_ref.extractall(extract_dir)\n",
        "#     print(\"Extraction completed.\")\n",
        "# else:\n",
        "#     print(f\"Directory already exists: {extract_dir}. Skipping extraction.\")"
      ],
      "metadata": {
        "id": "gQ6lLd02UOIU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52b10e71-f78a-4b51-c397-a6b1c695494a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Finetuned Model\n",
        "zip_path = '/content/drive/My Drive/iso9001-fine-tuned-model.zip'\n",
        "extract_dir = '/content/iso9001-fine-tuned-model'\n",
        "\n",
        "if not os.path.exists(extract_dir):\n",
        "    print(f\"Extracting zip file to: {extract_dir}\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_dir)\n",
        "    print(\"Extraction completed.\")\n",
        "else:\n",
        "    print(f\"Directory already exists: {extract_dir}. Skipping extraction.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L12uTH-QgVXY",
        "outputId": "b1603af4-7074-4e29-d6e0-c1ae4d3a0e5e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting zip file to: /content/iso9001-fine-tuned-model\n",
            "Extraction completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip /content/iso9001-finetuned-model.zip -d /content/iso9001-finetuned-model"
      ],
      "metadata": {
        "id": "7eE6G018PxB3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "YL0Nb1IqN4XT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training\n",
        "import logging\n",
        "from typing import List, Dict, Optional, Tuple, IO\n",
        "from fastapi import FastAPI, File, UploadFile\n",
        "import numpy as np\n",
        "import gc\n",
        "import io\n",
        "import PyPDF2\n",
        "# import fitz\n",
        "# import docx\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "# from iso_chatbot import ISO9001ChatBot\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "import os\n",
        "import sys\n",
        "import asyncio"
      ],
      "metadata": {
        "id": "DzYYni3UOkzF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util"
      ],
      "metadata": {
        "id": "LfqywE0df2jf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "MLcJSkSXe2xC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "VQVrs-QFVxAI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"NGROK_AUTH_TOKEN\"] = userdata.get(\"NGROK_AUTH_TOKEN\")"
      ],
      "metadata": {
        "id": "Z_zA3JxQSYqC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class RAG"
      ],
      "metadata": {
        "id": "wpWG0wzIOBgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass, field\n",
        "from typing import List\n",
        "\n",
        "@dataclass\n",
        "class ISO9001Requirement:\n",
        "    id: str\n",
        "    clause: str\n",
        "    title: str\n",
        "    criterion: str\n",
        "    example: str\n",
        "    keyword: List[str] = field(default_factory=list)"
      ],
      "metadata": {
        "id": "VgG8DMyhnpiJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict, Optional\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class ISO9001KnowledgeBase:\n",
        "    \"\"\"ISO 9001:2015 knowledge base with key requirements loaded from JSON\"\"\"\n",
        "\n",
        "    def __init__(self, json_path: str = None):\n",
        "        if json_path and os.path.exists(\"/content/drive/My Drive/rag_data.json\"):\n",
        "            self.requirements = self._load_iso_requirements(\"/content/drive/My Drive/rag_data.json\")\n",
        "            print(f\"✅ Loaded {len(self.requirements)} requirements from \\\"/content/drive/My Drive/rag_data.json\\\"\")\n",
        "        else:\n",
        "            logger.warning(\"JSON file not found, using sample requirements\")\n",
        "\n",
        "    def _load_iso_requirements(self, path: str) -> List[ISO9001Requirement]:\n",
        "        \"\"\"Load ISO 9001:2015 requirements from a JSON file\"\"\"\n",
        "        try:\n",
        "            with open(path, 'r', encoding='utf-8') as file:\n",
        "                data = json.load(file)\n",
        "\n",
        "                # Handle both list and single object formats\n",
        "                if isinstance(data, dict):\n",
        "                    # If it's a single object, wrap it in a list\n",
        "                    data = [data]\n",
        "                elif not isinstance(data, list):\n",
        "                    raise ValueError(\"JSON data must be a list or a single object\")\n",
        "\n",
        "                requirements = []\n",
        "                for item in data:\n",
        "                    if not isinstance(item, dict):\n",
        "                        logger.warning(f\"Skipping invalid item: {item}\")\n",
        "                        continue\n",
        "\n",
        "                    # Validate required fields\n",
        "                    required_fields = ['id', 'clause', 'title', 'criterion', 'example', 'keyword']\n",
        "                    if not all(field in item for field in required_fields):\n",
        "                        logger.warning(f\"Skipping item missing required fields: {item}\")\n",
        "                        continue\n",
        "\n",
        "                    # Ensure keyword' are lists\n",
        "                    item['keyword'] = item.get('keyword', [])\n",
        "                    if not isinstance(item['keyword'], list):\n",
        "                        item['keyword'] = [item['keyword']]\n",
        "\n",
        "                    # Create requirement object\n",
        "                    req = ISO9001Requirement(\n",
        "                        id=item['id'],\n",
        "                        clause=item['clause'],\n",
        "                        title=item['title'],\n",
        "                        criterion=item['criterion'],\n",
        "                        example=item['example'],\n",
        "                        keyword=item['keyword']\n",
        "                    )\n",
        "                    requirements.append(req)\n",
        "\n",
        "                return requirements\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error loading requirements from {path}: {e}\")\n",
        "            return self._generate_sample_criteria_data(10)\n",
        "\n",
        "    @staticmethod\n",
        "    def _generate_sample_criteria_data(num_samples: int = 10) -> list:\n",
        "        \"\"\"Tạo danh sách tiêu chí mẫu theo định dạng ISO 9001:2015\"\"\"\n",
        "        sample_titles = [\n",
        "            \"Phê duyệt tài liệu\", \"Kiểm soát thay đổi\", \"Xác định rủi ro\", \"Đào tạo và năng lực\",\n",
        "            \"Đánh giá nội bộ\", \"Hành động khắc phục\", \"Xem xét của lãnh đạo\", \"Kiểm soát thông tin dạng văn bản\",\n",
        "            \"Thỏa mãn yêu cầu khách hàng\", \"Lập kế hoạch chất lượng\"\n",
        "        ]\n",
        "\n",
        "        sample_criteria = [\n",
        "            \"Tài liệu phải được phê duyệt về tính phù hợp trước khi ban hành.\",\n",
        "            \"Mọi thay đổi phải được ghi lại và phê duyệt trước khi thực hiện.\",\n",
        "            \"Rủi ro và cơ hội phải được xác định và giải quyết.\",\n",
        "            \"Nhân sự phải được đào tạo và chứng minh năng lực.\",\n",
        "            \"Phải thực hiện đánh giá nội bộ định kỳ.\",\n",
        "            \"Cần có quy trình xử lý và ghi nhận hành động khắc phục.\",\n",
        "            \"Lãnh đạo phải định kỳ xem xét hệ thống quản lý chất lượng.\",\n",
        "            \"Thông tin dạng văn bản phải được kiểm soát chặt chẽ.\",\n",
        "            \"Tổ chức phải đảm bảo yêu cầu khách hàng được hiểu rõ và đáp ứng.\",\n",
        "            \"Phải thiết lập kế hoạch chất lượng cho các quá trình.\"\n",
        "        ]\n",
        "\n",
        "        sample_examples = [\n",
        "            \"Ví dụ: SOP có chữ ký xác nhận, ngày phê duyệt.\",\n",
        "            \"Ví dụ: Biên bản cập nhật thay đổi, có xác nhận.\",\n",
        "            \"Ví dụ: Danh sách rủi ro kèm hành động phòng ngừa.\",\n",
        "            \"Ví dụ: Hồ sơ đào tạo, chứng chỉ ISO.\",\n",
        "            \"Ví dụ: Báo cáo đánh giá nội bộ định kỳ.\",\n",
        "            \"Ví dụ: Biên bản hành động khắc phục sự cố.\",\n",
        "            \"Ví dụ: Biên bản họp lãnh đạo định kỳ.\",\n",
        "            \"Ví dụ: Kiểm soát phiên bản tài liệu.\",\n",
        "            \"Ví dụ: Hợp đồng và tài liệu yêu cầu khách hàng.\",\n",
        "            \"Ví dụ: Kế hoạch kiểm tra chất lượng sản phẩm.\"\n",
        "        ]\n",
        "\n",
        "        sample_keywords = [\n",
        "            [\"approval\", \"release\", \"sop\", \"phê duyệt\", \"document control\"],\n",
        "            [\"change\", \"revision\", \"update\", \"approval\"],\n",
        "            [\"risk\", \"opportunity\", \"risk register\"],\n",
        "            [\"training\", \"competence\", \"năng lực\"],\n",
        "            [\"internal audit\", \"evaluation\", \"đánh giá\"],\n",
        "            [\"correction\", \"action\", \"root cause\", \"khắc phục\"],\n",
        "            [\"review\", \"leadership\", \"họp lãnh đạo\"],\n",
        "            [\"version\", \"control\", \"document\", \"tài liệu\"],\n",
        "            [\"requirement\", \"customer\", \"đáp ứng\"],\n",
        "            [\"quality plan\", \"kế hoạch\", \"kiểm soát\"]\n",
        "        ]\n",
        "\n",
        "        sample_data = []\n",
        "        for i in range(num_samples):\n",
        "            sample_data.append({\n",
        "                \"id\": f\"CRIT-{i+1:03d}\",\n",
        "                \"clause\": f\"{random.randint(4, 10)}.{random.randint(1, 5)}\",\n",
        "                \"title\": sample_titles[i % len(sample_titles)],\n",
        "                \"criterion\": sample_criteria[i % len(sample_criteria)],\n",
        "                \"example\": sample_examples[i % len(sample_examples)],\n",
        "                \"keyword\": sample_keywords[i % len(sample_keywords)]\n",
        "            })\n",
        "\n",
        "        return sample_data\n",
        "\n",
        "    def get_clause_info(self, clause: str) -> Optional[ISO9001Requirement]:\n",
        "        \"\"\"Get information about a specific clause\"\"\"\n",
        "        for req in self.requirements:\n",
        "            if req.clause == clause:\n",
        "                return req\n",
        "        return None"
      ],
      "metadata": {
        "id": "XC7TL49onqIJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DocumentProcessor:\n",
        "    \"\"\"Process and extract text from various document formats\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_text_from_pdf(file: IO) -> str:\n",
        "        \"\"\"Extract text from PDF file-like object\"\"\"\n",
        "        try:\n",
        "            pdf_reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page in pdf_reader.pages:\n",
        "                page_text = page.extract_text()\n",
        "                if page_text:\n",
        "                    text += page_text + \"\\n\"\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error extracting text from PDF: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_text_from_docx(file_path: str) -> str:\n",
        "        \"\"\"Extract text from DOCX file\"\"\"\n",
        "        try:\n",
        "            doc = docx.Document(file_path)\n",
        "            text = \"\"\n",
        "            for paragraph in doc.paragraphs:\n",
        "                text += paragraph.text + \"\\n\"\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error extracting text from DOCX: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_text_from_txt(file_path: str) -> str:\n",
        "        \"\"\"Extract text from TXT file\"\"\"\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                return file.read()\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error extracting text from TXT: {e}\")\n",
        "            return \"\""
      ],
      "metadata": {
        "id": "UK7faHVCnr8Z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict, Optional, Tuple\n",
        "import logging\n",
        "import faiss\n",
        "import torch\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class VectorStore:\n",
        "    \"\"\"FAISS-based vector store for RAG with GPU optimization\"\"\"\n",
        "\n",
        "    def __init__(self, embedding_model: str = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"):\n",
        "        logger.info(f\"Initializing embedding model: {embedding_model}\")\n",
        "        self.embedding_model = SentenceTransformer(embedding_model)\n",
        "\n",
        "        # Move to GPU if available\n",
        "        if torch.cuda.is_available():\n",
        "            self.embedding_model = self.embedding_model.to(device)\n",
        "            logger.info(\"Embedding model moved to GPU\")\n",
        "\n",
        "        self.index = None\n",
        "        self.documents = []\n",
        "        self.embeddings = []\n",
        "\n",
        "    def add_documents(self, documents: List[str], batch_size: int = 32):\n",
        "        \"\"\"Add documents to the vector store with batching for GPU efficiency\"\"\"\n",
        "        logger.info(f\"Adding {len(documents)} documents to vector store\")\n",
        "\n",
        "        # Process in batches for memory efficiency\n",
        "        all_embeddings = []\n",
        "        for i in range(0, len(documents), batch_size):\n",
        "            batch = documents[i:i+batch_size]\n",
        "            batch_embeddings = self.embedding_model.encode(\n",
        "                batch,\n",
        "                convert_to_tensor=True,\n",
        "                show_progress_bar=True\n",
        "            )\n",
        "            all_embeddings.append(batch_embeddings.cpu().numpy())\n",
        "\n",
        "            # Clear GPU memory\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        # Concatenate all embeddings\n",
        "        embeddings = np.vstack(all_embeddings)\n",
        "\n",
        "        if self.index is None:\n",
        "            # Initialize FAISS index\n",
        "            dimension = embeddings.shape[1]\n",
        "            self.index = faiss.IndexFlatIP(dimension)  # Inner product for cosine similarity\n",
        "            logger.info(f\"Initialized FAISS index with dimension {dimension}\")\n",
        "\n",
        "        # Normalize embeddings for cosine similarity\n",
        "        faiss.normalize_L2(embeddings)\n",
        "\n",
        "        # Add to index\n",
        "        self.index.add(embeddings.astype('float32'))\n",
        "\n",
        "        # Store documents and embeddings\n",
        "        self.documents.extend(documents)\n",
        "        self.embeddings.extend(embeddings)\n",
        "\n",
        "    def search(self, query: str, k: int = 5) -> List[Tuple[str, float]]:\n",
        "        \"\"\"Search for similar documents\"\"\"\n",
        "        if self.index is None:\n",
        "            return []\n",
        "\n",
        "        # Generate query embedding\n",
        "        query_embedding = self.embedding_model.encode(\n",
        "            [query],\n",
        "            convert_to_tensor=True\n",
        "        ).cpu().numpy()\n",
        "        faiss.normalize_L2(query_embedding)\n",
        "\n",
        "        # Search\n",
        "        scores, indices = self.index.search(query_embedding.astype('float32'), k)\n",
        "\n",
        "        # Return results\n",
        "        results = []\n",
        "        for score, idx in zip(scores[0], indices[0]):\n",
        "            if idx < len(self.documents):\n",
        "                results.append((self.documents[idx], float(score)))\n",
        "\n",
        "        return results"
      ],
      "metadata": {
        "id": "Tdz0ZdDmnxqh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ISO9001ComplianceChecker:\n",
        "    \"\"\"Check document compliance against ISO 9001:2015 requirements\"\"\"\n",
        "\n",
        "    def __init__(self, knowledge_base: ISO9001KnowledgeBase):\n",
        "        self.kb = knowledge_base\n",
        "        self.embedding_model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "\n",
        "        # Move to GPU if available\n",
        "        if torch.cuda.is_available():\n",
        "            self.embedding_model = self.embedding_model.to(device)\n",
        "\n",
        "    def check_compliance(self, document_text: str) -> dict:\n",
        "        results = {\n",
        "            \"overall_score\": 0.0,\n",
        "            \"clause_compliance\": {},\n",
        "            \"missing_requirements\": [],\n",
        "            \"recommendations\": [],\n",
        "            \"found_evidence\": {}\n",
        "        }\n",
        "\n",
        "        total_score = 0\n",
        "        total_requirements = len(self.kb.requirements)\n",
        "\n",
        "        for req in self.kb.requirements:\n",
        "            clause_result = self._check_clause_compliance(document_text, req)\n",
        "            results[\"clause_compliance\"][req.clause] = clause_result\n",
        "            total_score += clause_result[\"score\"]\n",
        "\n",
        "            if clause_result[\"score\"] < 0.5:\n",
        "                results[\"missing_requirements\"].append({\n",
        "                    \"clause\": req.clause,\n",
        "                    \"title\": req.title,\n",
        "                    \"criterion\": req.criterion\n",
        "                })\n",
        "\n",
        "            if clause_result[\"evidence\"]:\n",
        "                results[\"found_evidence\"][req.clause] = clause_result[\"evidence\"]\n",
        "\n",
        "        results[\"overall_score\"] = total_score / total_requirements if total_requirements > 0 else 0\n",
        "        results[\"recommendations\"] = self._generate_recommendations(results)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _check_clause_compliance(self, document_text: str, requirement: dict) -> dict:\n",
        "        # 1. Tách văn bản thành câu\n",
        "        sentences = re.split(r'(?<=[.!?])\\s+', document_text.strip())\n",
        "\n",
        "        # 2. Mã hóa requirement tiêu chí\n",
        "        requirement_texts = [requirement.criterion]\n",
        "        if requirement.example:\n",
        "            requirement_texts.append(requirement.example)\n",
        "\n",
        "        req_embeddings = self.embedding_model.encode(requirement_texts, convert_to_tensor=True)\n",
        "\n",
        "        # 3. Mã hóa từng câu văn bản\n",
        "        sentence_embeddings = self.embedding_model.encode(sentences, convert_to_tensor=True)\n",
        "\n",
        "        matched_sentences = []\n",
        "        max_sim_score = 0.0\n",
        "\n",
        "        # 4. Tính similarity câu - từng yêu cầu, lấy câu có similarity > ngưỡng 0.6\n",
        "        for i, sent_emb in enumerate(sentence_embeddings):\n",
        "            for req_emb in req_embeddings:\n",
        "                sim_score = util.cos_sim(sent_emb, req_emb).item()\n",
        "                if sim_score > 0.6:\n",
        "                    matched_sentences.append(sentences[i].strip())\n",
        "                    if sim_score > max_sim_score:\n",
        "                        max_sim_score = sim_score\n",
        "\n",
        "        # 5. Tính điểm compliance dựa trên max similarity (giả sử max_sim_score phản ánh mức độ phù hợp)\n",
        "        final_score = round(max_sim_score, 4)\n",
        "\n",
        "        # 6. Trả về kết quả\n",
        "        return {\n",
        "            \"score\": final_score,\n",
        "            \"evidence\": matched_sentences\n",
        "        }\n",
        "    # def check_compliance(self, document_text: str) -> Dict:\n",
        "    #     \"\"\"Check document compliance against ISO 9001:2015\"\"\"\n",
        "    #     results = {\n",
        "    #         \"overall_score\": 0.0,\n",
        "    #         \"clause_compliance\": {},\n",
        "    #         \"missing_requirements\": [],\n",
        "    #         \"recommendations\": [],\n",
        "    #         \"found_evidence\": {}\n",
        "    #     }\n",
        "\n",
        "    #     total_score = 0\n",
        "    #     total_requirements = len(self.kb.requirements)\n",
        "\n",
        "    #     for req in self.kb.requirements:\n",
        "    #         clause_result = self._check_clause_compliance(document_text, req)\n",
        "    #         results[\"clause_compliance\"][req.clause] = clause_result\n",
        "    #         total_score += clause_result[\"score\"]\n",
        "\n",
        "    #         if clause_result[\"score\"] < 0.5:\n",
        "    #             results[\"missing_requirements\"].append({\n",
        "    #                 \"clause\": req.clause,\n",
        "    #                 \"title\": req.title,\n",
        "    #                 \"criterion\": req.criterion\n",
        "    #             })\n",
        "\n",
        "    #         if clause_result[\"evidence\"]:\n",
        "    #             results[\"found_evidence\"][req.clause] = clause_result[\"evidence\"]\n",
        "\n",
        "    #     results[\"overall_score\"] = total_score / total_requirements if total_requirements > 0 else 0\n",
        "    #     results[\"recommendations\"] = self._generate_recommendations(results)\n",
        "\n",
        "    #     return results\n",
        "\n",
        "    # def _check_clause_compliance(self, document_text: str, requirement: Dict) -> Dict:\n",
        "    #     doc_lower = document_text.lower()\n",
        "\n",
        "    #     # 1. Match keyword\n",
        "    #     keywords = requirement.keyword\n",
        "    #     keyword_matches = sum(1 for kw in keywords if kw.lower() in doc_lower)\n",
        "    #     keyword_score = keyword_matches / len(keywords) if keywords else 0\n",
        "\n",
        "    #     # 2. Match requirement & example\n",
        "    #     requirement_texts = [requirement.criterion]\n",
        "    #     if requirement.example:\n",
        "    #         requirement_texts.append(requirement.example)\n",
        "\n",
        "    #     evidence = []\n",
        "    #     requirement_matches = 0\n",
        "\n",
        "    #     for req in requirement_texts:\n",
        "    #         req_tokens = req.lower().split()\n",
        "    #         match_count = sum(1 for token in req_tokens if token in doc_lower)\n",
        "    #         if match_count >= len(req_tokens) * 0.4:\n",
        "    #             requirement_matches += 1\n",
        "    #             evidence.append(req)\n",
        "\n",
        "    #     requirement_score = requirement_matches / len(requirement_texts) if requirement_texts else 0\n",
        "\n",
        "    #     final_score = round(keyword_score * 0.4 + requirement_score * 0.6, 4)\n",
        "\n",
        "    #     return {\n",
        "    #         \"score\": final_score,\n",
        "    #         \"keyword_matches\": keyword_matches,\n",
        "    #         \"requirement_matches\": requirement_matches,\n",
        "    #         \"evidence\": evidence\n",
        "    #     }\n",
        "\n",
        "    def _generate_recommendations(self, results: Dict) -> List[str]:\n",
        "        recs = []\n",
        "\n",
        "        if results[\"overall_score\"] < 0.3:\n",
        "            recs.append(\"Mức độ tuân thủ tổng thể thấp. Cần rà soát toàn bộ tài liệu theo các điều khoản ISO 9001:2015.\")\n",
        "\n",
        "        if results[\"missing_requirements\"]:\n",
        "            recs.append(f\"Tài liệu thiếu nội dung ở {len(results['missing_requirements'])} điều khoản. Cần bổ sung.\")\n",
        "\n",
        "        for clause, result in results[\"clause_compliance\"].items():\n",
        "            if result[\"score\"] < 0.3:\n",
        "                matched = next((c for c in self.kb.requirements if c.clause == clause), None)\n",
        "                if matched:\n",
        "                    recs.append(\n",
        "                        f\"Điều khoản {clause} ({matched.title}): Thiếu minh chứng cho yêu cầu: {matched.criterion}.\"\n",
        "                    )\n",
        "        return recs"
      ],
      "metadata": {
        "id": "rcEbP8Y3n3c-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG Chatbot"
      ],
      "metadata": {
        "id": "vcAX0scZOLay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ISO9001RAGChatbot:\n",
        "    \"\"\"Main chatbot class combining RAG with DeepSeek model\"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str = \"vinai/PhoGPT-4B-Chat\"):\n",
        "        self.model_name = model_name\n",
        "        self.tokenizer = None\n",
        "        self.model = None\n",
        "        self.vector_store = VectorStore()\n",
        "        self.knowledge_base = ISO9001KnowledgeBase(json_path=\"/content/drive/My Drive/rag_data.json\")\n",
        "        self.compliance_checker = ISO9001ComplianceChecker(self.knowledge_base)\n",
        "        self.doc_processor = DocumentProcessor()\n",
        "\n",
        "        self._load_model()\n",
        "        self._setup_knowledge_base()\n",
        "\n",
        "    def _load_model(self):\n",
        "        \"\"\"Load the DeepSeek model and tokenizer\"\"\"\n",
        "        logger.info(f\"Loading model: {self.model_name}\")\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            self.model_name,\n",
        "            torch_dtype=torch.float16,\n",
        "            device_map=\"auto\"\n",
        "        ).to(device)\n",
        "\n",
        "        if self.tokenizer.pad_token is None:\n",
        "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "    def _setup_knowledge_base(self):\n",
        "        \"\"\"Setup the RAG knowledge base with ISO 9001:2015 content\"\"\"\n",
        "        logger.info(\"Setting up ISO 9001:2015 knowledge base\")\n",
        "        documents = []\n",
        "        for req in self.knowledge_base.requirements:\n",
        "            doc_text = f\"Clause {req.clause}: {req.title}\\n\"\n",
        "            doc_text += \"Requirements:\\n\" + \"\\n\".join(f\"- {r}\" for r in req.criterion)\n",
        "            documents.append(doc_text)\n",
        "            # for requirement in req.requirements:\n",
        "            #     req_doc = f\"Clause {req.clause} requirement: {requirement}\"\n",
        "            #     documents.append(req_doc)\n",
        "        self.vector_store.add_documents(documents)\n",
        "\n",
        "    def process_document(self, file: IO) -> Dict:\n",
        "        \"\"\"Process uploaded document (file-like object) and check compliance\"\"\"\n",
        "        logger.info(f\"Processing uploaded file: {file.name}\")\n",
        "\n",
        "        # Lấy đuôi file để xác định định dạng\n",
        "        ext = os.path.splitext(file.name)[1].lower()\n",
        "\n",
        "        if ext == '.pdf':\n",
        "            text = self.doc_processor.extract_text_from_pdf(file)\n",
        "        elif ext == '.docx':\n",
        "            text = self.doc_processor.extract_text_from_docx(file)\n",
        "        elif ext == '.txt':\n",
        "            text = self.doc_processor.extract_text_from_txt(file)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported file format\")\n",
        "\n",
        "        if not text.strip():\n",
        "            raise ValueError(\"Could not extract text from document\")\n",
        "\n",
        "        compliance_results = self.compliance_checker.check_compliance(text)\n",
        "        return {\n",
        "            \"document_text\": text,\n",
        "            \"compliance_results\": compliance_results\n",
        "        }\n",
        "\n",
        "    def generate_compliance_summary(self, compliance_results: Dict) -> Tuple[float, List[Tuple[str, Dict]]]:\n",
        "        \"\"\"Generate structured compliance summary with scores and clause details\"\"\"\n",
        "        summary = []\n",
        "\n",
        "        for clause, result in compliance_results[\"clause_compliance\"].items():\n",
        "            req = next(r for r in self.knowledge_base.requirements if r.clause == clause)\n",
        "            status = \"Compliant\" if result[\"score\"] >= 0.5 else \"Non-compliant\"\n",
        "            summary.append((\n",
        "                clause,\n",
        "                {\n",
        "                    \"title\": req.title,\n",
        "                    \"score\": result[\"score\"],\n",
        "                    \"status\": status,\n",
        "                    \"evidence\": result.get(\"evidence\", [])[:2] or [\"Không tìm thấy đoạn thông tin phù hợp theo yêu cầu.\"]\n",
        "                }\n",
        "            ))\n",
        "\n",
        "        return compliance_results[\"overall_score\"], summary"
      ],
      "metadata": {
        "id": "996cMpd1bpj0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finetuned Chatbot"
      ],
      "metadata": {
        "id": "KjJ32810OSo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ISO9001ChatBot:\n",
        "    def __init__(self, model_path: str):\n",
        "        self.base_model = \"Viet-Mistral/Vistral-7B-Chat\"\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.base_model, trust_remote_code=True)\n",
        "        if self.tokenizer.pad_token is None:\n",
        "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "        base = AutoModelForCausalLM.from_pretrained(\n",
        "            self.base_model,\n",
        "            torch_dtype=torch.bfloat16,\n",
        "            device_map=\"auto\",\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "\n",
        "        from peft import PeftModel\n",
        "        self.model = PeftModel.from_pretrained(base, model_path)\n",
        "        self.model.eval()\n",
        "\n",
        "    def _classify_question(self, question: str) -> str:\n",
        "        # Định nghĩa nội dung trao đổi theo format chat\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"Bạn là một trợ lý chuyên đánh giá câu hỏi người dùng về quản lý chất lượng (QMS).\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"\"\"Phân loại câu hỏi sau thành một trong hai loại:\n",
        "\n",
        "    1. document_search — nếu người dùng muốn tìm, xem hoặc yêu cầu một tài liệu cụ thể (như biểu mẫu, file, SOP, quy trình...).\n",
        "    2. normal_question — nếu người dùng đang hỏi về kiến thức, khái niệm, yêu cầu của ISO 9001:2015.\n",
        "\n",
        "    Chỉ trả lời duy nhất một từ: document_search hoặc normal_question.\n",
        "\n",
        "    Câu hỏi: \"{question}\"\n",
        "    Loại:\"\"\"\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        # Áp dụng chat template của model\n",
        "        prompt = self.tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True\n",
        "        )\n",
        "\n",
        "        # Tokenize prompt theo chuẩn của Vistral\n",
        "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = self.model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=10,\n",
        "                do_sample=False,  # sinh chắc chắn\n",
        "                pad_token_id=self.tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        result = self.tokenizer.decode(\n",
        "            output[0][inputs[\"input_ids\"].shape[1]:],\n",
        "            skip_special_tokens=True\n",
        "        ).strip().lower()\n",
        "\n",
        "        # Phân loại kết quả\n",
        "        if \"document_search\" in result:\n",
        "            return \"document_search\"\n",
        "        elif \"normal_question\" in result:\n",
        "            return \"normal_question\"\n",
        "        else:\n",
        "            return \"unknown\"\n",
        "\n",
        "    def _extract_keywords(self, question: str) -> List[str]:\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"Bạn là trợ lý QMS. Nhiệm vụ của bạn là trích xuất từ khóa tìm kiếm từ câu hỏi tiếng Việt.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"\"\"Câu hỏi: \"{question}\"\n",
        "\n",
        "        Hãy trích xuất các từ khóa chính (dưới dạng tiếng Việt), phân cách bằng dấu phẩy.\n",
        "        Không dịch sang tiếng Anh. Chỉ liệt kê từ khóa, không giải thích.\n",
        "        \"\"\"\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        prompt = self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "        print(prompt)\n",
        "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = self.model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=30,\n",
        "                do_sample=False,\n",
        "                pad_token_id=self.tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        result = self.tokenizer.decode(output[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True)\n",
        "        return [kw.strip() for kw in result.split(\",\") if kw.strip()]\n",
        "\n",
        "    def _chat_sync(self, question: str) -> str:\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"Bạn là trợ lý ISO 9001:2015. Dựa trên ngữ cảnh cuộc trò chuyện, hãy trả lời câu hỏi mới nhất một cách chi tiết, chính xác và thực tế.\"\n",
        "            }\n",
        "        ] + [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"\"\"{question}\n",
        "\n",
        "    Trả lời: \"\"\"\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        # Tạo prompt chat đúng định dạng\n",
        "        prompt = self.tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True\n",
        "        )\n",
        "        print(prompt)\n",
        "        inputs = self.tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=2048, padding=True)\n",
        "        inputs = {k: v.to(self.model.device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = self.model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=300,\n",
        "                temperature=0.7,\n",
        "                do_sample=True,\n",
        "                pad_token_id=self.tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        return self.tokenizer.decode(output[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True)\n",
        "\n",
        "    async def chat(self, question: str) -> str:\n",
        "        loop = asyncio.get_event_loop()\n",
        "        return await loop.run_in_executor(None, self._chat_sync, question)\n"
      ],
      "metadata": {
        "id": "2KkM-A-pOlfU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a07a950-c8ca-4aa2-c479-05cbcd681be3"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-284' coro=<Server.serve() done, defined at /usr/local/lib/python3.11/dist-packages/uvicorn/server.py:68> exception=KeyboardInterrupt()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/main.py\", line 580, in run\n",
            "    server.run()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 66, in run\n",
            "    return asyncio.run(self.serve(sockets=sockets))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 30, in run\n",
            "    return loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
            "    self._run_once()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 133, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 360, in __wakeup\n",
            "    self.__step()\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 277, in __step\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 69, in serve\n",
            "    with self.capture_signals():\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 144, in __exit__\n",
            "    next(self.gen)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 330, in capture_signals\n",
            "    signal.raise_signal(captured_signal)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# API"
      ],
      "metadata": {
        "id": "gutyn06tObN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Danh sách từ khóa QMS\n",
        "qms_keywords = [\n",
        "    \"iso 9001\", \"hệ thống quản lý chất lượng\", \"qms\", \"tiêu chuẩn iso\", \"iso\",\n",
        "    \"đánh giá nội bộ\", \"đánh giá chất lượng\", \"kiểm tra chất lượng\", \"cải tiến liên tục\",\n",
        "    \"kiểm soát chất lượng\", \"đào tạo chất lượng\", \"rà soát quản lý\", \"phân tích nguyên nhân\",\n",
        "    \"hành động khắc phục\", \"hành động phòng ngừa\", \"báo cáo không phù hợp\",\n",
        "    \"quản lý rủi ro\", \"giám sát và đo lường\", \"Điều khoản\", \"Sổ tay hướng dẫn\",\n",
        "    \"quản lý tài liệu\", \"kiểm soát tài liệu\", \"lưu trữ tài liệu\", \"phiên bản tài liệu\",\n",
        "    \"bản phát hành\", \"phê duyệt tài liệu\", \"thay đổi tài liệu\", \"phân phối tài liệu\",\n",
        "    \"thu hồi tài liệu\", \"tài liệu hướng dẫn\", \"biểu mẫu\", \"quy trình\", \"quy định\",\n",
        "    \"hồ sơ chất lượng\", \"tài liệu viết tay\", \"tài liệu điện tử\", \"hướng dẫn công việc\",\n",
        "    \"kiểm soát thay đổi\", \"ghi nhận tài liệu\", \"truy cập tài liệu\", \"hướng dẫn\",\n",
        "    \"trách nhiệm\", \"quyền hạn\", \"người phụ trách\", \"bộ phận quản lý chất lượng\",\n",
        "    \"phân công nhiệm vụ\", \"người soạn thảo\", \"người phê duyệt\", \"người sử dụng tài liệu\",\n",
        "    \"đào tạo nhân viên\", \"giám sát\", \"điều khoản\", \"tài liệu\", \"hướng dẫn\",\n",
        "    \"đánh giá tài liệu\", \"kiểm tra hiệu quả\", \"đo lường hiệu quả\", \"phản hồi\",\n",
        "    \"cải tiến tài liệu\", \"kiểm toán nội bộ\", \"báo cáo kiểm toán\", \"khắc phục sai sót\",\n",
        "    \"rủi ro\", \"quản lý rủi ro\", \"biện pháp phòng ngừa\", \"hành động khắc phục\",\n",
        "    \"điều tra nguyên nhân\", \"xử lý sự cố\", \"ncr\", \"hướng dẫn\", \"viết\", \"phiên bản\", \"loại\",\n",
        "    \"hệ thống iso\", \"quy trình làm việc\", \"tiêu chí chất lượng\", \"bảng kiểm tra\",\n",
        "    \"hồ sơ kiểm tra\", \"biên bản họp\", \"chứng nhận iso\", \"mẫu biểu\", \"biểu mẫu\", \"quy trình\",\n",
        "    \"quy định\", \"sổ tay chất lượng\", \"sổ tay hướng dẫn\", \"mục\", \"nội dung\",\n",
        "    \"hồ sơ chất lượng\", \"tài liệu viết tay\", \"tài liệu điện tử\", \"hướng dẫn công việc\",\n",
        "    \"kiểm soát thay đổi\", \"ghi nhận tài liệu\", \"truy cập tài liệu\"\n",
        "]\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Chuyển về chữ thường\n",
        "    text = text.lower()\n",
        "    # Loại bỏ dấu câu\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "    # Loại bỏ khoảng trắng thừa\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "def classify_question_keyword_based(question):\n",
        "    question_processed = preprocess_text(question)\n",
        "    for keyword in qms_keywords:\n",
        "        if keyword in question_processed:\n",
        "            return \"related\"\n",
        "    return \"unrelated\"\n",
        "\n",
        "# Ví dụ test\n",
        "questions = [\n",
        "    \"Tổ chức có nên lưu trữ tài liệu giấy không?\",\n",
        "    \"AI sẽ thay thế con người trong tương lai?\",\n",
        "    \"Quy trình phê duyệt tài liệu diễn ra như thế nào?\",\n",
        "    \"Hôm nay thời tiết thế nào?\",\n",
        "    \"Làm sao để kiểm soát thay đổi tài liệu hiệu quả?\",\n",
        "    \"giải thích về NCR\"\n",
        "]\n",
        "\n",
        "for q in questions:\n",
        "    result = classify_question_keyword_based(q)\n",
        "    print(f\"Câu hỏi: {q}\\nPhân loại: {result}\\n\")"
      ],
      "metadata": {
        "id": "uWAgZ1uwA3xK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bbe694b-d3ba-4084-8f20-bdd5d8acf224"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Câu hỏi: Tổ chức có nên lưu trữ tài liệu giấy không?\n",
            "Phân loại: related\n",
            "\n",
            "Câu hỏi: AI sẽ thay thế con người trong tương lai?\n",
            "Phân loại: unrelated\n",
            "\n",
            "Câu hỏi: Quy trình phê duyệt tài liệu diễn ra như thế nào?\n",
            "Phân loại: related\n",
            "\n",
            "Câu hỏi: Hôm nay thời tiết thế nào?\n",
            "Phân loại: unrelated\n",
            "\n",
            "Câu hỏi: Làm sao để kiểm soát thay đổi tài liệu hiệu quả?\n",
            "Phân loại: related\n",
            "\n",
            "Câu hỏi: giải thích về NCR\n",
            "Phân loại: related\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "chatbot = ISO9001ChatBot(\"./iso9001-fine-tuned-model/content/iso9001-fine-tuned-model\")\n",
        "# rag_chatbot = ISO9001RAGChatbot(\"./iso9001-rag-model/content/iso9001-rag-model\")\n",
        "# rag_chatbot = ISO9001RAGChatbot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e4bee34ac20b41b9a4166e0652333f84",
            "a3a0cec726a54510af55df717d74ee3d",
            "31b1cad8936642d0be316bbc3c2c5342",
            "2a0e51f2358048b795cead94847cb893",
            "e05befbd2efa445fb5d681325961f262",
            "2b860a0407534cbb906281e72f90ec61",
            "924b7938731d4e0c8f4c7fee7bdec65e",
            "710357eb2b4c48cdb81834981fe6cd5a",
            "fa6533bc06374532a477d571f43c6a9e",
            "69e92852b95745ee86a4ca4e71f145a4",
            "785b6751684b47efa15646c28dc8e37f"
          ]
        },
        "id": "m5q7_D-hbI6c",
        "outputId": "9127be89-1d0e-4280-f288-3182dbda4085"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4bee34ac20b41b9a4166e0652333f84"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for q in [\n",
        "    \"có tài liệu y tế ở đây không\",\n",
        "    \"trình bày yêu cầu của mục 7.5 trong ISO 9001\",\n",
        "    \"cho tôi xem biểu mẫu đánh giá nội bộ\",\n",
        "    \"Hướng dẫn viết\",\n",
        "    \"gồm những phiên bản nào\",\n",
        "    \"Yêu cầu thế nào\"\n",
        "]:\n",
        "    label = chatbot._classify_question(q)\n",
        "    print(f\"[TEST] {q} --> {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K21hhFl45LjX",
        "outputId": "8c6e4bb1-efee-4346-8794-9ce2bfa6d8e2"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] có tài liệu y tế ở đây không --> document_search\n",
            "[TEST] trình bày yêu cầu của mục 7.5 trong ISO 9001 --> normal_question\n",
            "[TEST] cho tôi xem biểu mẫu đánh giá nội bộ --> document_search\n",
            "[TEST] Hướng dẫn viết --> normal_question\n",
            "[TEST] gồm những phiên bản nào --> document_search\n",
            "[TEST] Yêu cầu thế nào --> normal_question\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cho phép gọi từ frontend khác domain nếu cần\n",
        "app = FastAPI(title=\"ISO 9001 Chatbot API\")\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],  # Hoặc liệt kê cụ thể: [\"http://localhost:3000\"]\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "class ClauseResult(BaseModel):\n",
        "    clause: str\n",
        "    title: str\n",
        "    status: str\n",
        "    score: float\n",
        "    evidence: List[str] = []\n",
        "\n",
        "class AnalyzeResponse(BaseModel):\n",
        "    score: float\n",
        "    clause_results: List[ClauseResult]\n",
        "\n",
        "# class AnalyzeResponse(BaseModel):\n",
        "#     criterion: str\n",
        "#     status: str\n",
        "#     score: float\n",
        "#     explanation: str\n",
        "\n",
        "class KeywordResponse(BaseModel):\n",
        "    keywords: List[str]\n",
        "\n",
        "class ChatRequest(BaseModel):\n",
        "    question: str\n",
        "\n",
        "class ChatResponse(BaseModel):\n",
        "    response: str\n",
        "\n",
        "class ChatMessage(BaseModel):\n",
        "    role: str\n",
        "    content: str\n",
        "\n",
        "class ChatFullRequest(BaseModel):\n",
        "    question: str\n",
        "    history_messages: List[ChatMessage]\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def root():\n",
        "    return {\"message\": \"ISO 9001 Chatbot API is running\"}\n",
        "\n",
        "@app.post(\"/get-label\", response_model=ChatResponse)\n",
        "async def chat(req: ChatRequest):\n",
        "    if not req.question.strip():\n",
        "        raise HTTPException(status_code=400, detail=\"Question is required.\")\n",
        "\n",
        "    try:\n",
        "        print(\"Calling chatbot...\")\n",
        "        if(classify_question_keyword_based(req.question) == \"unrelated\"):\n",
        "            response = \"unknown\"\n",
        "        else:\n",
        "            response = chatbot._classify_question(req.question)\n",
        "\n",
        "        return {\"response\": response}\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "@app.post(\"/extract-keywords\", response_model=KeywordResponse)\n",
        "async def extract_keywords(req: ChatRequest):\n",
        "    if not req.question.strip():\n",
        "        raise HTTPException(status_code=400, detail=\"Question is required.\")\n",
        "\n",
        "    try:\n",
        "        keywords = chatbot._extract_keywords(req.question)\n",
        "        return {\"keywords\": keywords}\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "@app.post(\"/chat\", response_model=ChatResponse)\n",
        "async def chat(req: ChatRequest):\n",
        "    if not req.question.strip():\n",
        "        raise HTTPException(status_code=400, detail=\"Question is required.\")\n",
        "\n",
        "    try:\n",
        "        response = chatbot._chat_sync(req.question)\n",
        "        return {\"response\": response}\n",
        "\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "# @app.post(\"/analyze\", response_model=AnalyzeResponse)\n",
        "# async def analyze(document: UploadFile = File(...)):\n",
        "#     try:\n",
        "#         # Đọc nội dung file\n",
        "#         content = await document.read()\n",
        "#         file_stream = io.BytesIO(content)\n",
        "#         file_stream.name = document.filename  # Đặt tên để xác định định dạng\n",
        "\n",
        "#         # Gọi hàm xử lý tài liệu\n",
        "#         doc_results = rag_chatbot.extract_text_from_pdf(file_stream)\n",
        "\n",
        "#         # Tạo bản báo cáo (tuỳ theo bạn muốn hiển thị gì)\n",
        "#         score, clause_results_raw = rag_chatbot.generate_compliance_summary(doc_results[\"compliance_results\"])\n",
        "\n",
        "#         # Chuyển clause_results_raw sang dạng List[ClauseResult]\n",
        "#         clause_results = [\n",
        "#             ClauseResult(\n",
        "#                 clause=clause,\n",
        "#                 title=result[\"title\"],\n",
        "#                 status=result[\"status\"],\n",
        "#                 score=result[\"score\"],\n",
        "#                 evidence=result.get(\"evidence\", [])\n",
        "#             )\n",
        "#             for clause, result in clause_results_raw\n",
        "#         ]\n",
        "\n",
        "#         return {\n",
        "#             \"score\": score,\n",
        "#             \"clause_results\": clause_results\n",
        "#         }\n",
        "#     except Exception as e:\n",
        "#         raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "@app.post(\"/analyze\", response_model=AnalyzeResponse)\n",
        "async def analyze(document: UploadFile = File(...)):\n",
        "    try:\n",
        "        # Đọc nội dung file\n",
        "        content = await document.read()\n",
        "        file_stream = io.BytesIO(content)\n",
        "        file_stream.name = document.filename  # Đặt tên để xác định định dạng\n",
        "\n",
        "        # Gọi hàm xử lý tài liệu\n",
        "        doc_results = rag_chatbot.process_document(file_stream)\n",
        "\n",
        "        # Tạo bản báo cáo (tuỳ theo bạn muốn hiển thị gì)\n",
        "        score, clause_results_raw = rag_chatbot.generate_compliance_summary(doc_results[\"compliance_results\"])\n",
        "\n",
        "        # Chuyển clause_results_raw sang dạng List[ClauseResult]\n",
        "        clause_results = [\n",
        "            ClauseResult(\n",
        "                clause=clause,\n",
        "                title=result[\"title\"],\n",
        "                status=result[\"status\"],\n",
        "                score=result[\"score\"],\n",
        "                evidence=result.get(\"evidence\", [])\n",
        "            )\n",
        "            for clause, result in clause_results_raw\n",
        "        ]\n",
        "\n",
        "        return {\n",
        "            \"score\": score,\n",
        "            \"clause_results\": clause_results\n",
        "        }\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))"
      ],
      "metadata": {
        "id": "jwIkUgvMO4DD"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run"
      ],
      "metadata": {
        "id": "SSmdE9dyOepl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "from google.colab import userdata\n",
        "\n",
        "# Áp dụng patch cho asyncio để chạy trong notebook\n",
        "nest_asyncio.apply()\n",
        "\n",
        "NGROK_AUTH_TOKEN = userdata.get('NGROK_AUTH_TOKEN') # Get from Colab secrets if stored there\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN) # Uncomment and use this line if needed\n",
        "\n",
        "# Mở cổng 8000 ra internet\n",
        "public_url = ngrok.connect(addr=8000, domain=\"ample-wildly-parrot.ngrok-free.app\")\n",
        "print(\"Public URL:\", public_url)\n",
        "\n",
        "# Chạy server\n",
        "uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQxWYMdGPY0z",
        "outputId": "f12d4655-1673-4262-a76a-bf6e6c38d519"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://ample-wildly-parrot.ngrok-free.app\" -> \"http://localhost:8000\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [313]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling chatbot...\n",
            "INFO:     2001:ee0:4f0e:f780:cc26:5f94:bcac:af00:0 - \"POST /get-label HTTP/1.1\" 200 OK\n",
            "<s>[INST] <<SYS>>\n",
            "Bạn là trợ lý ISO 9001:2015. Dựa trên ngữ cảnh cuộc trò chuyện, hãy trả lời câu hỏi mới nhất một cách chi tiết, chính xác và thực tế.\n",
            "<</SYS>>\n",
            "\n",
            "Người dùng: Hướng dẫn viết\n",
            "Bot:  Đánh giá hiệu suất hoạt động của phòng ban dựa trên các chỉ số KPIs đã định, xác định điểm mạnh và yếu, đề xuất hành động cải tiến phù hợp. \n",
            "Người dùng: Biểu mẫu là gì\n",
            "Bot:  Biểu mẫu là tài liệu chuẩn hóa được sử dụng để thu thập dữ liệu, ghi nhận thông tin theo định dạng chuẩn, giúp tăng tính nhất quán, giảm sai sót và dễ dàng kiểm tra, đánh giá. Biểu mẫu có thể bao gồm các bảng, checklist, phiếu kiểm tra, hoặc hồ sơ ghi nhận kết quả, có mã số, phiên bản và người sử dụng rõ ràng. Biểu mẫu được kiểm soát trong hệ thống tài liệu và có thể sử dụng lặp lại hoặc tùy chỉnh phù hợp với từng lần sử dụng. \n",
            "Người dùng: hướng dẫn viết\n",
            "Bot: document_search\n",
            "Người dùng: hướng dẫn viết\n",
            "Bot: \n",
            "\n",
            "    Trả lời: [/INST]\n",
            "INFO:     2001:ee0:4f0e:f780:cc26:5f94:bcac:af00:0 - \"POST /chat HTTP/1.1\" 200 OK\n",
            "Calling chatbot...\n",
            "INFO:     2001:ee0:4f0e:f780:cc26:5f94:bcac:af00:0 - \"POST /get-label HTTP/1.1\" 200 OK\n",
            "<s>[INST] <<SYS>>\n",
            "Bạn là trợ lý ISO 9001:2015. Dựa trên ngữ cảnh cuộc trò chuyện, hãy trả lời câu hỏi mới nhất một cách chi tiết, chính xác và thực tế.\n",
            "<</SYS>>\n",
            "\n",
            "Người dùng: Biểu mẫu là gì\n",
            "Bot:  Biểu mẫu là tài liệu chuẩn hóa được sử dụng để thu thập dữ liệu, ghi nhận thông tin theo định dạng chuẩn, giúp tăng tính nhất quán, giảm sai sót và dễ dàng kiểm tra, đánh giá. Biểu mẫu có thể bao gồm các bảng, checklist, phiếu kiểm tra, hoặc hồ sơ ghi nhận kết quả, có mã số, phiên bản và người sử dụng rõ ràng. Biểu mẫu được kiểm soát trong hệ thống tài liệu và có thể sử dụng lặp lại hoặc tùy chỉnh phù hợp với từng lần sử dụng. \n",
            "Người dùng: hướng dẫn viết\n",
            "Bot: document_search\n",
            "Người dùng: hướng dẫn viết\n",
            "Bot:  Dựa trên ngữ cảnh cuộc trò chuyện, có thể bạn đang gặp khó khăn trong việc viết tài liệu hướng dẫn công việc chuẩn. Dưới đây là mẫu định dạng chuẩn để bạn tham khảo:\n",
            "\n",
            "**Mục đích:**\n",
            "Tài liệu này nhằm hướng dẫn quy trình thực hiện [tên công việc], đảm bảo tính nhất quán, chính xác và tuân thủ yêu cầu chất lượng.\n",
            "\n",
            "**Phạm vi áp dụng:**\n",
            "Áp dụng cho [phòng ban/bộ phận], tại [địa điểm], đối với nhân viên thực hiện [tên công việc].\n",
            "\n",
            "**Trách nhiệm:**\n",
            "- [Tên bạn] – Quản lý chất lượng: Kiểm tra tính tuân thủ, cập nhật tài liệu\n",
            "- [Tên người viết] – [Chức danh] bộ phận [Phòng ban]: Soạn thảo và duy trì tài liệu\n",
            "- [Tên người dùng] – [Chức danh] bộ phận [Phòng ban]: Sử dụng và phản hồi cải tiến\n",
            "\n",
            "**Nội dung chi tiết:**\n",
            "1. [Bước 1: Mô tả bước đầu tiên]\n",
            "2. [Bước 2: Mô tả bước thứ hai]\n",
            "   - [Lưu ý hoặc cảnh báo]\n",
            "3. [Bước 3: Mô tả bước cuối cùng]\n",
            "\n",
            "**Phụ lục:**\n",
            "- [Đính kèm biểu mẫu liên quan]\n",
            "- [Danh sách kiểm tra hoặc bảng tính]\n",
            "\n",
            "**Tài\n",
            "Người dùng: biểu mẫu là gì\n",
            "Bot: \n",
            "\n",
            "    Trả lời: [/INST]\n",
            "INFO:     2001:ee0:4f0e:f780:cc26:5f94:bcac:af00:0 - \"POST /chat HTTP/1.1\" 200 OK\n",
            "Calling chatbot...\n",
            "INFO:     2001:ee0:4f0e:f780:cc26:5f94:bcac:af00:0 - \"POST /get-label HTTP/1.1\" 200 OK\n",
            "<s>[INST] <<SYS>>\n",
            "Bạn là trợ lý ISO 9001:2015. Dựa trên ngữ cảnh cuộc trò chuyện, hãy trả lời câu hỏi mới nhất một cách chi tiết, chính xác và thực tế.\n",
            "<</SYS>>\n",
            "\n",
            "Người dùng: hướng dẫn viết\n",
            "Bot: document_search\n",
            "Người dùng: hướng dẫn viết\n",
            "Bot:  Dựa trên ngữ cảnh cuộc trò chuyện, có thể bạn đang gặp khó khăn trong việc viết tài liệu hướng dẫn công việc chuẩn. Dưới đây là mẫu định dạng chuẩn để bạn tham khảo:\n",
            "\n",
            "**Mục đích:**\n",
            "Tài liệu này nhằm hướng dẫn quy trình thực hiện [tên công việc], đảm bảo tính nhất quán, chính xác và tuân thủ yêu cầu chất lượng.\n",
            "\n",
            "**Phạm vi áp dụng:**\n",
            "Áp dụng cho [phòng ban/bộ phận], tại [địa điểm], đối với nhân viên thực hiện [tên công việc].\n",
            "\n",
            "**Trách nhiệm:**\n",
            "- [Tên bạn] – Quản lý chất lượng: Kiểm tra tính tuân thủ, cập nhật tài liệu\n",
            "- [Tên người viết] – [Chức danh] bộ phận [Phòng ban]: Soạn thảo và duy trì tài liệu\n",
            "- [Tên người dùng] – [Chức danh] bộ phận [Phòng ban]: Sử dụng và phản hồi cải tiến\n",
            "\n",
            "**Nội dung chi tiết:**\n",
            "1. [Bước 1: Mô tả bước đầu tiên]\n",
            "2. [Bước 2: Mô tả bước thứ hai]\n",
            "   - [Lưu ý hoặc cảnh báo]\n",
            "3. [Bước 3: Mô tả bước cuối cùng]\n",
            "\n",
            "**Phụ lục:**\n",
            "- [Đính kèm biểu mẫu liên quan]\n",
            "- [Danh sách kiểm tra hoặc bảng tính]\n",
            "\n",
            "**Tài\n",
            "Người dùng: biểu mẫu là gì\n",
            "Bot:  Biểu mẫu là tài liệu chuẩn hóa dùng để thu thập, ghi nhận thông tin theo định dạng chuẩn, giúp tăng tính nhất quán, giảm sai sót và dễ dàng kiểm tra, đánh giá. Biểu mẫu có mã số, phiên bản và người sử dụng rõ ràng, có thể sử dụng lặp lại hoặc tùy chỉnh phù hợp với từng lần sử dụng. Biểu mẫu là một công cụ quan trọng trong hệ thống quản lý chất lượng và được kiểm soát chặt chẽ trong danh mục tài liệu. \n",
            "Người dùng: gồm các mục nào\n",
            "Bot: \n",
            "\n",
            "    Trả lời: [/INST]\n",
            "INFO:     2001:ee0:4f0e:f780:cc26:5f94:bcac:af00:0 - \"POST /chat HTTP/1.1\" 200 OK\n",
            "Calling chatbot...\n",
            "INFO:     2001:ee0:4f0e:f780:cc26:5f94:bcac:af00:0 - \"POST /get-label HTTP/1.1\" 200 OK\n",
            "<s>[INST] <<SYS>>\n",
            "Bạn là trợ lý ISO 9001:2015. Dựa trên ngữ cảnh cuộc trò chuyện, hãy trả lời câu hỏi mới nhất một cách chi tiết, chính xác và thực tế.\n",
            "<</SYS>>\n",
            "\n",
            "Người dùng: hướng dẫn viết\n",
            "Bot:  Dựa trên ngữ cảnh cuộc trò chuyện, có thể bạn đang gặp khó khăn trong việc viết tài liệu hướng dẫn công việc chuẩn. Dưới đây là mẫu định dạng chuẩn để bạn tham khảo:\n",
            "\n",
            "**Mục đích:**\n",
            "Tài liệu này nhằm hướng dẫn quy trình thực hiện [tên công việc], đảm bảo tính nhất quán, chính xác và tuân thủ yêu cầu chất lượng.\n",
            "\n",
            "**Phạm vi áp dụng:**\n",
            "Áp dụng cho [phòng ban/bộ phận], tại [địa điểm], đối với nhân viên thực hiện [tên công việc].\n",
            "\n",
            "**Trách nhiệm:**\n",
            "- [Tên bạn] – Quản lý chất lượng: Kiểm tra tính tuân thủ, cập nhật tài liệu\n",
            "- [Tên người viết] – [Chức danh] bộ phận [Phòng ban]: Soạn thảo và duy trì tài liệu\n",
            "- [Tên người dùng] – [Chức danh] bộ phận [Phòng ban]: Sử dụng và phản hồi cải tiến\n",
            "\n",
            "**Nội dung chi tiết:**\n",
            "1. [Bước 1: Mô tả bước đầu tiên]\n",
            "2. [Bước 2: Mô tả bước thứ hai]\n",
            "   - [Lưu ý hoặc cảnh báo]\n",
            "3. [Bước 3: Mô tả bước cuối cùng]\n",
            "\n",
            "**Phụ lục:**\n",
            "- [Đính kèm biểu mẫu liên quan]\n",
            "- [Danh sách kiểm tra hoặc bảng tính]\n",
            "\n",
            "**Tài\n",
            "Người dùng: biểu mẫu là gì\n",
            "Bot:  Biểu mẫu là tài liệu chuẩn hóa dùng để thu thập, ghi nhận thông tin theo định dạng chuẩn, giúp tăng tính nhất quán, giảm sai sót và dễ dàng kiểm tra, đánh giá. Biểu mẫu có mã số, phiên bản và người sử dụng rõ ràng, có thể sử dụng lặp lại hoặc tùy chỉnh phù hợp với từng lần sử dụng. Biểu mẫu là một công cụ quan trọng trong hệ thống quản lý chất lượng và được kiểm soát chặt chẽ trong danh mục tài liệu. \n",
            "Người dùng: gồm các mục nào\n",
            "Bot:  Biểu mẫu thường bao gồm các mục sau:\n",
            "\n",
            "1. **Mục tiêu hoặc nội dung:** Phần khai báo mục đích hoặc nội dung cần ghi nhận\n",
            "2. **Thông tin cơ bản:** Các trường thông tin cơ bản như tên, mã số, ngày tháng,…\n",
            "3. **Nội dung chi tiết:** Phần chính để ghi nhận thông tin chi tiết theo từng bước hoặc yêu cầu\n",
            "4. **Ký xác nhận:** Nơi người thực hiện, người duyệt hoặc người liên quan ký xác nhận\n",
            "5. **Phụ lục hoặc biểu mẫu kèm theo:** Nếu cần, phần này cho phép đính kèm hoặc ghi chú thêm.\n",
            "\n",
            "Ngoài ra, biểu mẫu cần có mã số, phiên bản, người sử dụng và ngày hiệu lực rõ ràng. Biểu mẫu chuẩn hóa giúp tiết kiệm thời gian ghi nhận, giảm sai sót và tăng tính nhất quán trong việc thu thập và lưu trữ dữ liệu. \n",
            "Người dùng: sổ tay chất lượng là gì\n",
            "Bot: \n",
            "\n",
            "    Trả lời: [/INST]\n",
            "INFO:     2001:ee0:4f0e:f780:cc26:5f94:bcac:af00:0 - \"POST /chat HTTP/1.1\" 200 OK\n",
            "Calling chatbot...\n",
            "INFO:     2001:ee0:4f0e:f780:cc26:5f94:bcac:af00:0 - \"POST /get-label HTTP/1.1\" 200 OK\n",
            "<s>[INST] <<SYS>>\n",
            "Bạn là trợ lý ISO 9001:2015. Dựa trên ngữ cảnh cuộc trò chuyện, hãy trả lời câu hỏi mới nhất một cách chi tiết, chính xác và thực tế.\n",
            "<</SYS>>\n",
            "\n",
            "Người dùng: biểu mẫu là gì\n",
            "Bot:  Biểu mẫu là tài liệu chuẩn hóa dùng để thu thập, ghi nhận thông tin theo định dạng chuẩn, giúp tăng tính nhất quán, giảm sai sót và dễ dàng kiểm tra, đánh giá. Biểu mẫu có mã số, phiên bản và người sử dụng rõ ràng, có thể sử dụng lặp lại hoặc tùy chỉnh phù hợp với từng lần sử dụng. Biểu mẫu là một công cụ quan trọng trong hệ thống quản lý chất lượng và được kiểm soát chặt chẽ trong danh mục tài liệu. \n",
            "Người dùng: gồm các mục nào\n",
            "Bot:  Biểu mẫu thường bao gồm các mục sau:\n",
            "\n",
            "1. **Mục tiêu hoặc nội dung:** Phần khai báo mục đích hoặc nội dung cần ghi nhận\n",
            "2. **Thông tin cơ bản:** Các trường thông tin cơ bản như tên, mã số, ngày tháng,…\n",
            "3. **Nội dung chi tiết:** Phần chính để ghi nhận thông tin chi tiết theo từng bước hoặc yêu cầu\n",
            "4. **Ký xác nhận:** Nơi người thực hiện, người duyệt hoặc người liên quan ký xác nhận\n",
            "5. **Phụ lục hoặc biểu mẫu kèm theo:** Nếu cần, phần này cho phép đính kèm hoặc ghi chú thêm.\n",
            "\n",
            "Ngoài ra, biểu mẫu cần có mã số, phiên bản, người sử dụng và ngày hiệu lực rõ ràng. Biểu mẫu chuẩn hóa giúp tiết kiệm thời gian ghi nhận, giảm sai sót và tăng tính nhất quán trong việc thu thập và lưu trữ dữ liệu. \n",
            "Người dùng: sổ tay chất lượng là gì\n",
            "Bot:  Sổ tay chất lượng (Quality Manual) là tài liệu tổng hợp mô tả hệ thống quản lý chất lượng của tổ chức, bao gồm phạm vi áp dụng, quy trình chính, trách nhiệm, nguồn lực và các yêu cầu ISO 9001 mà tổ chức cam kết tuân thủ. Sổ tay chất lượng là tài liệu tham khảo cho toàn bộ hệ thống, giúp các bên liên quan hiểu rõ cách thức tổ chức duy trì và cải tiến chất lượng. \n",
            "Người dùng: Hướng dẫn viết\n",
            "Bot: \n",
            "\n",
            "    Trả lời: [/INST]\n",
            "INFO:     2001:ee0:4f0e:f780:cc26:5f94:bcac:af00:0 - \"POST /chat HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [313]\n"
          ]
        }
      ]
    }
  ]
}